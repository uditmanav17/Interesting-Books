{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch13 Loading and Preprocessing Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b22d6b3cbe3f465881076fc6411dd089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59c52928d9654454aea31f00769fd800",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ad38b68cdda4832b736593927738662",
              "IPY_MODEL_19f64c60bf6c4803a7a6cca6dfaf2972"
            ]
          }
        },
        "59c52928d9654454aea31f00769fd800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ad38b68cdda4832b736593927738662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b16c68ac494f464d91e8ee5603297a72",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fa3da74b007484b89b0ebafa8d26069"
          }
        },
        "19f64c60bf6c4803a7a6cca6dfaf2972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0ac2adee520d475eaca005ac5f5ffc82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  5.81 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9263bb01633a4547b963f76e391469a4"
          }
        },
        "b16c68ac494f464d91e8ee5603297a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fa3da74b007484b89b0ebafa8d26069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ac2adee520d475eaca005ac5f5ffc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9263bb01633a4547b963f76e391469a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZi8uMfue7ep",
        "colab_type": "text"
      },
      "source": [
        "# Loading and Preprocessing Data\n",
        "\n",
        "In this chapter, we will cover the Data API, the TFRecord format, and how to create custom preprocessing layers and use the standard Keras ones. We will also take a quick look at a few related projects from TensorFlow’s ecosystem:\n",
        "\n",
        "* **TF Transform (tf.Transform)** <br>\n",
        "Makes it possible to write a single preprocessing function that can be run in batch mode on your full training set, before training (to speed it up), and then exported to a TF Function and incorporated into your trained model so that once it is deployed in production it can take care of preprocessing new instances on the fly.\n",
        "\n",
        "* **TF Datasets (TFDS)** <br>\n",
        "Provides a convenient function to download many common datasets of all kinds, including large ones like ImageNet, as well as convenient dataset objects to manipulate them using the Data API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7j90bOLxdKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -U tensorflow-transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wf13U7WUS5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o66VdGO6S5Me",
        "colab_type": "text"
      },
      "source": [
        "## The Data API\n",
        "The whole Data API revolves around the concept of a dataset: representing a sequence of data items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPvbOMZDs9An",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d0f96e4f-9aad-41d2-9b14-c440ee42d138"
      },
      "source": [
        "X = tf.range(10)\n",
        "print(f\"X - {X}\")\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "print(f\"Dataset - {dataset}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X - [0 1 2 3 4 5 6 7 8 9]\n",
            "Dataset - <TensorSliceDataset shapes: (), types: tf.int32>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr0r70ZKUycn",
        "colab_type": "text"
      },
      "source": [
        "The from_tensor_slices() function takes a tensor and creates a tf.data.Dataset whose elements are all the slices of X (along the first dimension), so this dataset contains 10 items: tensors 0, 1, 2, …, 9. In this case we would have obtained the same dataset if we had used **tf.data.Dataset.range(10)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cbP6LyAUnEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "1bd4eaae-48a2-4f02-85e5-95301c9bcb16"
      },
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWioWJV2U7px",
        "colab_type": "text"
      },
      "source": [
        "### Chaining Transformations\n",
        "Once you have a dataset, you can apply all sorts of transformations to it by calling its transformation methods. Each method returns a new dataset, so you can chain transformations like this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVxT6IUvU5rp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "42fd3f03-9549-45d8-f505-56281350f4a2"
      },
      "source": [
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmhDR3jGVp-J",
        "colab_type": "text"
      },
      "source": [
        "In this example, we first call the repeat() method on the original dataset, and it returns a new dataset that will repeat the items of the original dataset three times. Of course, this will not copy all the data in memory three times! (If you call this method with no arguments, the new dataset will repeat the source dataset forever, so the code that iterates over the dataset will have to decide when to stop.) Then we call the batch() method on this new dataset, and again this creates a new dataset. This one will group the items of the previous dataset in batches of seven items. Finally, we iterate over the items of this final dataset. As you can see, the batch() method had to output a final batch of size two instead of seven, but you can call it with drop_remain der=True if you want it to drop this final batch so that all batches have the exact same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3KDVNu8VppS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "1fbebb0c-3fd0-492a-a21b-7e2149fc379e"
      },
      "source": [
        "# using map to transform dataset\n",
        "dataset = dataset.map(lambda x:x*2)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4E8fzpCXAWD",
        "colab_type": "text"
      },
      "source": [
        "While the map() method applies a transformation to each item, the apply() method applies a transformation to the dataset as a whole. For example, the following code applies the unbatch() function to the dataset (this function is currently experimental, but it will most likely move to the core API in a future release). Each item in the new dataset will be a single-integer tensor instead of a batch of seven integers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSz1Ct2-VMiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "eac35216-fb80-40a0-d37d-b3455d4b925b"
      },
      "source": [
        "#dataset = dataset.apply(tf.data.experimental.unbatch()) # Now deprecateddataset2 = dataset.unbatch()\n",
        "for item in dataset2:\n",
        "    print(item)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d2367bfcd7c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#dataset = dataset.apply(tf.data.experimental.unbatch()) # Now deprecateddataset2 = dataset.unbatch()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaerJ3TZWZmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filter dataset\n",
        "dataset2 = dataset2.filter(lambda x: x < 10)\n",
        "for ele in dataset2:\n",
        "    print(ele)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVtsbgITYWrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check few entries of dataset\n",
        "for ele in dataset2.take(6):\n",
        "    print(ele)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMagrRBQYqAs",
        "colab_type": "text"
      },
      "source": [
        "### Shuffling Data\n",
        "A simple way to shuffle the instances is using the shuffle() method. It will create a new dataset that will start by filling up a buffer with the first items of the source dataset. Then, whenever it is asked for an item, it will pull one out randomly from the buffer and replace it with a fresh one from the source dataset, until it has iterated entirely through the source dataset. At this point it continues to pull out items randomly from the buffer until it is empty. You must specify the buffer size, and it is important to make it large enough, or else shuffling will not be very effective. Just don’t exceed the amount of RAM you have, and even if you have plenty of it, there’s no need to go beyond the dataset’s size. You can provide a random seed if you want the same random order every time you run your program. For example, the following code creates and displays a dataset containing the integers 0 to 9, repeated 3 times, shuffled using a buffer of size 5 and a random seed of 42, and batched with a batch size of 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwhvTO3fYhoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "6bb681ea-e87c-4f8a-a276-e3b341bf422b"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10).repeat(3) # 0 to 9, three times\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42, \n",
        "                          reshuffle_each_iteration=False).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 5 1 7 0 8 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([0 4 3 1 5 6 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([6 7 2 9 0 3 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([2 8 4 6 8 9 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 1], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvhz3bBsNPvt",
        "colab_type": "text"
      },
      "source": [
        "#### Interleaving lines from multiple files\n",
        "First we are gonna download california house dataset and split it into multiple files. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdiL6d6DmGbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2554e246-417f-4118-d758-114106aa5d81"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, \n",
        "                                                              housing.target.reshape(-1, 1), \n",
        "                                                              random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, \n",
        "                                                      y_train_full, \n",
        "                                                      random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean = scaler.mean_\n",
        "X_std = scaler.scale_"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3OIofmUN6nO",
        "colab_type": "text"
      },
      "source": [
        "For a very large dataset that does not fit in memory, you will typically want to split it into many files first, then have TensorFlow read these files in parallel. To demonstrate this, let's start by splitting the housing dataset and save it to 20 CSV files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u21WENnJc12S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO8Gz3fLN982",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "train_data = np.c_[X_train, y_train]\n",
        "valid_data = np.c_[X_valid, y_valid]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
        "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0neNZBJYOEcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b6302315-378d-4e4f-98b3-3dfe9f3f7809"
      },
      "source": [
        "# peek at data\n",
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(train_filepaths[0]).head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>MedianHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.5214</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.049945</td>\n",
              "      <td>1.106548</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>1.605993</td>\n",
              "      <td>37.63</td>\n",
              "      <td>-122.43</td>\n",
              "      <td>1.442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.3275</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.490060</td>\n",
              "      <td>0.991054</td>\n",
              "      <td>3464.0</td>\n",
              "      <td>3.443340</td>\n",
              "      <td>33.69</td>\n",
              "      <td>-117.39</td>\n",
              "      <td>1.687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.1000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7.542373</td>\n",
              "      <td>1.591525</td>\n",
              "      <td>1328.0</td>\n",
              "      <td>2.250847</td>\n",
              "      <td>38.44</td>\n",
              "      <td>-122.98</td>\n",
              "      <td>1.621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.1736</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.289003</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>1054.0</td>\n",
              "      <td>2.695652</td>\n",
              "      <td>33.55</td>\n",
              "      <td>-117.70</td>\n",
              "      <td>2.621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0549</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.312457</td>\n",
              "      <td>1.085092</td>\n",
              "      <td>3297.0</td>\n",
              "      <td>2.244384</td>\n",
              "      <td>33.93</td>\n",
              "      <td>-116.93</td>\n",
              "      <td>0.956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  ...  Latitude  Longitude  MedianHouseValue\n",
              "0  3.5214      15.0  3.049945  ...     37.63    -122.43             1.442\n",
              "1  5.3275       5.0  6.490060  ...     33.69    -117.39             1.687\n",
              "2  3.1000      29.0  7.542373  ...     38.44    -122.98             1.621\n",
              "3  7.1736      12.0  6.289003  ...     33.55    -117.70             2.621\n",
              "4  2.0549      13.0  5.312457  ...     33.93    -116.93             0.956\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTrWtNXxOOe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "8f160575-4db5-438d-af55-224d023b7752"
      },
      "source": [
        "with open(train_filepaths[0]) as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline(), end=\"\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
            "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
            "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
            "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
            "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gAz9JDpORmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "f51ecdeb-ee85-4db6-e47b-1c64d4de68f9"
      },
      "source": [
        "train_filepaths"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_train_00.csv',\n",
              " 'datasets/housing/my_train_01.csv',\n",
              " 'datasets/housing/my_train_02.csv',\n",
              " 'datasets/housing/my_train_03.csv',\n",
              " 'datasets/housing/my_train_04.csv',\n",
              " 'datasets/housing/my_train_05.csv',\n",
              " 'datasets/housing/my_train_06.csv',\n",
              " 'datasets/housing/my_train_07.csv',\n",
              " 'datasets/housing/my_train_08.csv',\n",
              " 'datasets/housing/my_train_09.csv',\n",
              " 'datasets/housing/my_train_10.csv',\n",
              " 'datasets/housing/my_train_11.csv',\n",
              " 'datasets/housing/my_train_12.csv',\n",
              " 'datasets/housing/my_train_13.csv',\n",
              " 'datasets/housing/my_train_14.csv',\n",
              " 'datasets/housing/my_train_15.csv',\n",
              " 'datasets/housing/my_train_16.csv',\n",
              " 'datasets/housing/my_train_17.csv',\n",
              " 'datasets/housing/my_train_18.csv',\n",
              " 'datasets/housing/my_train_19.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM-LtleGOzKT",
        "colab_type": "text"
      },
      "source": [
        "#### Interleaving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4xVc0kbOTGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "4036c4d4-8231-46d2-ca97-6758df2b2d24"
      },
      "source": [
        "# default shuffle=True\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
        "\n",
        "# shuffled files\n",
        "for filepath in filepath_dataset:\n",
        "    print(filepath)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Vrtl_BPU3P",
        "colab_type": "text"
      },
      "source": [
        "Next, you can call the interleave() method to read from five files at a time and interleave their lines (skipping the first line of each file, which is the header row, using the skip() method):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XvV-Q9mO3MU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "                                      cycle_length=n_readers)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENKTkai_Psaf",
        "colab_type": "text"
      },
      "source": [
        "The interleave() method will create a dataset that will pull five file paths from the filepath_dataset, and for each one it will call the function you gave it (a lambda in this example) to create a new dataset (in this case a TextLineDataset). To be clear, at this stage there will be seven datasets in all: the filepath dataset, the interleave dataset, and the five TextLineDatasets created internally by the interleave dataset. When we iterate over the interleave dataset, it will cycle through these five TextLineDatasets, reading one line at a time from each until all datasets are out of items. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3sr62haQSAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "44c82a6e-db9c-472b-ba99-3d23b501373f"
      },
      "source": [
        "for line in dataset.take(5):\n",
        "    print(line.numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418'\n",
            "b'2.4792,24.0,3.4547038327526134,1.1341463414634145,2251.0,3.921602787456446,34.18,-118.38,2.0'\n",
            "b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67'\n",
            "b'2.1856,41.0,3.7189873417721517,1.0658227848101265,803.0,2.0329113924050635,32.76,-117.12,1.205'\n",
            "b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xxPHMB3RJbr",
        "colab_type": "text"
      },
      "source": [
        "These are the first rows (ignoring the header row) of five CSV files, chosen randomly. Looks good! But as you can see, these are just byte strings; we need to parse them and scale the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MnSKA0zP6cF",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKw5NPugRsnf",
        "colab_type": "text"
      },
      "source": [
        "Converting str to tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTJyuYAxPtPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_inputs = 8 # X_train.shape[-1]\n",
        "\n",
        "@tf.function\n",
        "def preprocess(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    x = tf.stack(fields[:-1])\n",
        "    y = tf.stack(fields[-1:])\n",
        "    return (x - X_mean) / X_std, y"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVQiqgqySrKA",
        "colab_type": "text"
      },
      "source": [
        "Code Walkthrough - <br>\n",
        "* First, the code assumes that we have precomputed the mean and standard deviation of each feature in the training set. X_mean and X_std are just 1D tensors (or NumPy arrays) containing eight floats, one per input feature. <br>\n",
        "* The preprocess() function takes one CSV line and starts by parsing it. For this it uses the tf.io.decode_csv() function, which takes two arguments: the first is the line to parse, and the second is an array containing the default value for each column in the CSV file. This array tells TensorFlow not only the default value for each column, but also the number of columns and their types. In this example, we tell it that all feature columns are floats and that missing values should default to 0, but we provide an empty array of type tf.float32 as the default value for the last column (the target): the array tells TensorFlow that this column contains floats, but that there is no default value, so it will raise an exception if it encounters a missing value.<br>\n",
        "* The decode_csv() function returns a list of scalar tensors (one per column), but we need to return 1D tensor arrays. So we call tf.stack() on all tensors except for the last one (the target): this will stack these tensors into a 1D array. We then do the same for the target value (this makes it a 1D tensor array with a single value, rather than a scalar tensor).<br>\n",
        "* Finally, we scale the input features by subtracting the feature means and then dividing by the feature standard deviations, and we return a tuple containing the scaled features and the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4e1WLGfSqQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "da24d212-471e-45f3-9ea1-8224eccf541a"
      },
      "source": [
        "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.16579157,  1.216324  , -0.05204565, -0.39215982, -0.5277444 ,\n",
              "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJfi_u3qUq6N",
        "colab_type": "text"
      },
      "source": [
        "### Putting Everything Together\n",
        "To make the code reusable, let’s put together everything we have discussed so far into a small helper function: it will create and return a dataset that will efficiently load California housing data from multiple CSV files, preprocess it, shuffle it, optionally repeat it, and batch it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc7Z-ua6TG9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
        "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
        "                       n_parse_threads=5, batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1) # for prefetching check next section"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM4scTw3VRKv",
        "colab_type": "text"
      },
      "source": [
        "### Prefetching\n",
        "By calling prefetch(1) at the end, we are creating a dataset that will do its best to always be one batch ahead. In other words, while our training algorithm is working on one batch, the dataset will already be working in parallel on getting the next batch ready (e.g., reading the data from disk and preprocessing it). This can improve performance dramatically. If we also ensure that loading and preprocessing are multithreaded (by setting num_parallel_calls when calling interleave() and map()), we can exploit multiple cores on the CPU and hopefully make preparing one batch of data shorter than running a training step on the GPU. \n",
        "\n",
        "If the dataset is small enough to fit in memory, you can significantly speed up training by using the dataset’s cache() method to cache its content to RAM. You should generally do this after loading and preprocessing the data, but before shuffling,repeating, batching, and prefetching. This way, each instance will only be read and preprocessed once (instead of once per epoch), but the data will still be shuffled differently at each epoch, and the next batch will still be prepared in advance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLeOnVhPWWrB",
        "colab_type": "text"
      },
      "source": [
        "### Using the Dataset with tf.keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjCqWDXXWzZo",
        "colab_type": "text"
      },
      "source": [
        "Now we can use the csv_reader_dataset() function to create a dataset for the training set. Note that we do not need to repeat it, as this will be taken care of by tf.keras. We also create datasets for the validation set and the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1I6G_gwWpQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
        "valid_set = csv_reader_dataset(valid_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsMznI3cW7Sb",
        "colab_type": "text"
      },
      "source": [
        "And now we can simply build and train a Keras model using these datasets.4 All we need to do is pass the training and validation datasets to the fit() method, instead of X_train, y_train, X_valid, and y_valid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egyOs_AdW6_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxInPbSuW6aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adQT0o1nXLS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "3dc27764-2121-49dd-fb5c-56feec00aba6"
      },
      "source": [
        "batch_size = 32\n",
        "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
        "          validation_data=valid_set)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 1.6148 - val_loss: 3.1276\n",
            "Epoch 2/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.7262 - val_loss: 0.6612\n",
            "Epoch 3/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.6410 - val_loss: 0.6123\n",
            "Epoch 4/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5822 - val_loss: 0.5635\n",
            "Epoch 5/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5771 - val_loss: 0.5382\n",
            "Epoch 6/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5484 - val_loss: 0.5181\n",
            "Epoch 7/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5311 - val_loss: 0.5023\n",
            "Epoch 8/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5158 - val_loss: 0.4863\n",
            "Epoch 9/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 0.4677\n",
            "Epoch 10/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.4949 - val_loss: 0.4611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff5d77f7f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfksEwgiXM9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "03d494ea-91c3-4d65-de16-a50c1071fe94"
      },
      "source": [
        "model.evaluate(test_set, steps=len(X_test) // batch_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "161/161 [==============================] - 0s 2ms/step - loss: 0.4785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47854503989219666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlhfXj_KXPRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "71fe1a7f-2cde-4910-debb-5936072980ca"
      },
      "source": [
        "new_set = test_set.map(lambda X, y: X) # we could instead just pass test_set, Keras would ignore the labels\n",
        "X_new = X_test\n",
        "model.predict(new_set, steps=len(X_new) // batch_size)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9943755],\n",
              "       [2.036063 ],\n",
              "       [3.0165668],\n",
              "       ...,\n",
              "       [3.0062077],\n",
              "       [1.9939625],\n",
              "       [3.2436008]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH-1ebCcYcbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "258e27b1-8b9e-4dc4-9048-2442f35b740d"
      },
      "source": [
        "# Here is a short description of each method in the Dataset class:\n",
        "\n",
        "for m in dir(tf.data.Dataset):\n",
        "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
        "        func = getattr(tf.data.Dataset, m)\n",
        "        if hasattr(func, \"__doc__\"):\n",
        "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "● apply()              Applies a transformation function to this dataset.\n",
            "● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n",
            "● batch()              Combines consecutive elements of this dataset into batches.\n",
            "● cache()              Caches the elements in this dataset.\n",
            "● cardinality()        Returns the cardinality of the dataset, if known.\n",
            "● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
            "● element_spec()       The type specification of an element of this dataset.\n",
            "● enumerate()          Enumerates the elements of this dataset.\n",
            "● filter()             Filters this dataset according to `predicate`.\n",
            "● flat_map()           Maps `map_func` across this dataset and flattens the result.\n",
            "● from_generator()     Creates a `Dataset` whose elements are generated by `generator`.\n",
            "● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n",
            "● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n",
            "● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n",
            "● list_files()         A dataset of all files matching one or more glob patterns.\n",
            "● map()                Maps `map_func` across the elements of this dataset.\n",
            "● options()            Returns the options for this dataset and its inputs.\n",
            "● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n",
            "● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n",
            "● range()              Creates a `Dataset` of a step-separated range of values.\n",
            "● reduce()             Reduces the input dataset to a single element.\n",
            "● repeat()             Repeats this dataset so each original value is seen `count` times.\n",
            "● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
            "● shuffle()            Randomly shuffles the elements of this dataset.\n",
            "● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n",
            "● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n",
            "● unbatch()            Splits elements of a dataset into multiple elements.\n",
            "● window()             Combines (nests of) input elements into a dataset of (nests of) windows.\n",
            "● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n",
            "● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-zKWAS1Xnuf",
        "colab_type": "text"
      },
      "source": [
        "## TF Record Format\n",
        "The TFRecord format is TensorFlow’s preferred format for storing large amounts of data and reading it efficiently. It is a very simple binary format that just contains a sequence of binary records of varying sizes (each record is comprised of a length, a CRC checksum to check that the length was not corrupted, then the actual data, and finally a CRC checksum for the data). You can easily create a TFRecord file using the tf.io.TFRecordWriter class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSOhX3ovXTqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And this is the second record\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_47--6UY52O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f5befba0-db8d-4ade-b19a-55c4d056f92b"
      },
      "source": [
        "# reading tfrecord\n",
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHjHA2RTZf31",
        "colab_type": "text"
      },
      "source": [
        "You can read multiple TFRecord files with just one TFRecordDataset. By default it will read them one at a time, but if you set num_parallel_reads=3, it will read 3 at a time in parallel and interleave their records:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC1YrfDaY-jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "8576f76a-b874-40dc-a12c-3c9adcb72bb9"
      },
      "source": [
        "filepaths = [\"my_test_{}.tfrecord\".format(i) for i in range(5)]\n",
        "for i, filepath in enumerate(filepaths):\n",
        "    with tf.io.TFRecordWriter(filepath) as f:\n",
        "        for j in range(3):\n",
        "            f.write(\"File {} record {}\".format(i, j).encode(\"utf-8\"))\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=3)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'File 0 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 1 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 2 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 0 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 1 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 2 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 0 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 1 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 2 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 3 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 4 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 3 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 4 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 3 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 4 record 2', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnM6y8q-Zkxf",
        "colab_type": "text"
      },
      "source": [
        "### Compressed TFRecord\n",
        "It can sometimes be useful to compress your TFRecord files, especially if they need to be loaded via a network connection. You can create a compressed TFRecord file by setting the options argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eR8BeO-ZiA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And this is the second record\")\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww3rl3z7ZuZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "39e14fb4-70dd-4c16-a948-667a528bb5ec"
      },
      "source": [
        "# reading compressed TFRecord\n",
        "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],compression_type=\"GZIP\")\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKRFaK_3bcXY",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the Input Features\n",
        "Preparing your data for a neural network requires converting all features into numerical features, generally normalizing them, and more. In particular, if your data contains categorical features or text features, they need to be converted to numbers. This can be done ahead of time when preparing your data files, using any tool you like (e.g., NumPy, pandas, or Scikit-Learn). Alternatively, you can preprocess your data on the fly when loading it with the Data API (e.g., using the dataset’s map() method, as we saw earlier), or you can include a preprocessing layer directly in your model. Let’s look at this last option now.\n",
        "\n",
        "For example, here is how you can implement a standardization layer using a Lambda layer. For each feature, it subtracts the mean and divides by its standard deviation (plus a tiny smoothing term to avoid division by zero):\n",
        "\n",
        "```\n",
        "means = np.mean(X_train, axis=0, keepdims=True)\n",
        "stds = np.std(X_train, axis=0, keepdims=True)\n",
        "eps = keras.backend.epsilon()\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Lambda(lambda inputs: (inputs - means) / (stds + eps)),\n",
        "    [...] # other layers\n",
        "])\n",
        "```\n",
        "\n",
        "That’s not too hard! However, you may prefer to use a nice self-contained custom layer (much like Scikit-Learn’s StandardScaler), rather than having global variables like means and stds dangling around:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thnrGqHubbYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Standardization(keras.layers.Layer):\n",
        "    def adapt(self, data_sample):\n",
        "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
        "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3FqGu5Pc9Fx",
        "colab_type": "text"
      },
      "source": [
        "Before you can use this standardization layer, you will need to adapt it to your dataset by calling the adapt() method and passing it a data sample. This will allow it to use the appropriate mean and standard deviation for each feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXQh-1-KZ2dB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_layer = Standardization()\n",
        "std_layer.adapt(X_train[:100])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deGlOxIKd3y3",
        "colab_type": "text"
      },
      "source": [
        "This sample must be large enough to be representative of your dataset, but it does not have to be the full training set: in general, a few hundred randomly selected instances will suffice (however, this depends on your task). Next, you can use this preprocessing layer like a normal layer:\n",
        "```\n",
        "model = keras.Sequential()\n",
        "model.add(std_layer)\n",
        "[...] # create the rest of the model\n",
        "model.compile([...])\n",
        "model.fit([...])\n",
        "```\n",
        "\n",
        "Checkout **keras.layers.Normalization** layer will probably be available. It will work very much like our custom Standardization layer: first, create the layer, then adapt it to your dataset by passing a data sample to the adapt() method, and finally use the layer normally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omvMTOjreh0-",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Categorical Features Using One-Hot Vectors\n",
        "Consider the ocean_proximity feature in the California housing dataset we explored in Chapter 2: it is a categorical feature with five possible values: \"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", and \"ISLAND\". We need to encode this feature before we feed it to a neural network. Since there are very few categories, we can use one-hot encoding. For this, we first need to map each category to its index (0 to 4), which can be done using a lookup table:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Edd8oWrd0Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz63tlafgNsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFfmQs3IgPvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "f91b5213-c559-4b71-ed01-b9fca9fb1e51"
      },
      "source": [
        "housing = load_housing_data()\n",
        "housing.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  ...  median_house_value  ocean_proximity\n",
              "0    -122.23     37.88  ...            452600.0         NEAR BAY\n",
              "1    -122.22     37.86  ...            358500.0         NEAR BAY\n",
              "2    -122.24     37.85  ...            352100.0         NEAR BAY\n",
              "3    -122.25     37.85  ...            341300.0         NEAR BAY\n",
              "4    -122.25     37.85  ...            342200.0         NEAR BAY\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWTpEzUWl35O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
        "indices = tf.range(len(vocab), dtype=tf.int64)\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
        "num_oov_buckets = 2\n",
        "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEZxtMIPl8mJ",
        "colab_type": "text"
      },
      "source": [
        "Code Walkthrough -\n",
        "We first define the vocabulary: this is the list of all possible categories.\n",
        "* Then we create a tensor with the corresponding indices (0 to 4).\n",
        "* Next, we create an initializer for the lookup table, passing it the list of categories and their corresponding indices. In this example, we already have this data, so we use a KeyValueTensorInitializer; but if the categories were listed in a text file (with one category per line), we would use a TextFileInitializer instead.\n",
        "* In the last two lines we create the lookup table, giving it the initializer and specifying the number of out-of-vocabulary (oov) buckets. If we look up a category that does not exist in the vocabulary, the lookup table will compute a hash of this category and use it to assign the unknown category to one of the oov buckets. Their indices start after the known categories, so in this example the indices of the two oov buckets are 5 and 6.\n",
        "\n",
        "Why use oov buckets? Well, if the number of categories is large (e.g., zip codes, cities, words, products, or users) and the dataset is large as well, or it keeps changing, then getting the full list of categories may not be convenient. One solution is to define the vocabulary based on a data sample (rather than the whole training set) and add some oov buckets for the other categories that were not in the data sample. The more unknown categories you expect to find during training, the more oov buckets you should use. Indeed, if there are not enough oov buckets, there will be collisions: different categories will end up in the same bucket, so the neural network will not be able to distinguish them (at least not based on this feature).\n",
        "\n",
        "Now let’s use the lookup table to encode a small batch of categorical features to onehot vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBrhIzygl8An",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53b6d4ec-25b5-4e20-f4e1-92d4d7331243"
      },
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "print(cat_indices)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([3 5 1 1], shape=(4,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmeJ9aVnmWNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "6a828b48-fa54-42e6-9413-878125067bc3"
      },
      "source": [
        "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
        "cat_one_hot"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI23pu1smdnd",
        "colab_type": "text"
      },
      "source": [
        "As you can see, \"NEAR BAY\" was mapped to index 3, the unknown category \"DESERT\" was mapped to one of the two oov buckets (at index 5), and \"INLAND\" was mapped to index 1, twice. Then we used tf.one_hot() to one-hot encode these indices. Notice that we have to tell this function the total number of indices, which is equal to the vocabulary size plus the number of oov buckets.\n",
        "\n",
        "Just like earlier, it wouldn’t be too difficult to bundle all of this logic into a nice selfcontained class. Its adapt() method would take a data sample and extract all the distinct categories it contains. It would create a lookup table to map each category to its index (including unknown categories using oov buckets). Then its call() method would use the lookup table to map the input categories to their indices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n3IIeA5ndKE",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Categorical Features Using Embeddings\n",
        "An embedding is a trainable dense vector that represents a category. By default, embeddings are initialized randomly, so for example the \"NEAR BAY\" category could be represented initially by a random vector such as [0.131, 0.890], while the \"NEAR OCEAN\" category might be represented by another random vector such as [0.631, 0.791]. In this example, we use 2D embeddings, but the number of dimensions is a hyperparameter you can tweak. Since these embeddings are trainable, they will gradually improve during training; and as they represent fairly similar categories, Gradient Descent will certainly end up pushing them closer together, while it will tend to move them away from the \"INLAND\" category’s embedding. Indeed, the better the representation, the easier it will be for the neural network to make accurate predictions, so training tends to make embeddings useful representations of the categories. This is called representation learning.\n",
        "\n",
        "Let’s look at how we could implement embeddings manually, to understand how they work (then we will use a simple Keras layer instead). First, we need to create an embedding matrix containing each category’s embedding, initialized randomly; it will have one row per category and per oov bucket, and one column per embedding dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0jvqBYpmZH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 2\n",
        "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
        "embedding_matrix = tf.Variable(embed_init)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NubJvufoGIy",
        "colab_type": "text"
      },
      "source": [
        "In this example we are using 2D embeddings, but as a rule of thumb embeddings typ‐ ically have 10 to 300 dimensions, depending on the task and the vocabulary size (you will have to tune this hyperparameter).\n",
        "\n",
        "This embedding matrix is a random 6 × 2 matrix, stored in a variable (so it can be tweaked by Gradient Descent during training):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjUoO8UqnfR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "01f80b31-d388-47a9-d0d7-3370198a7a14"
      },
      "source": [
        "embedding_matrix"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
              "array([[0.7413678 , 0.62854624],\n",
              "       [0.01738465, 0.3431449 ],\n",
              "       [0.51063764, 0.3777541 ],\n",
              "       [0.07321596, 0.02137029],\n",
              "       [0.2871771 , 0.4710616 ],\n",
              "       [0.6936141 , 0.07321334],\n",
              "       [0.93251204, 0.20843053]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdE7N-2usOz6",
        "colab_type": "text"
      },
      "source": [
        "Now let’s encode the same batch of categorical features as earlier, but this time using these embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqptBsnwoI7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ab739c5-ba90-41fd-e8c4-3fe0915612a6"
      },
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_khfoC_lsTYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "92dae8e1-e3a9-4dd7-ac99-fef7fdd877d2"
      },
      "source": [
        "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0.07321596, 0.02137029],\n",
              "       [0.6936141 , 0.07321334],\n",
              "       [0.01738465, 0.3431449 ],\n",
              "       [0.01738465, 0.3431449 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEXUNil_sagv",
        "colab_type": "text"
      },
      "source": [
        "The tf.nn.embedding_lookup() function looks up the rows in the embedding matrix, at the given indices—that’s all it does. For example, the lookup table says that the \"INLAND\" category is at index 1, so the tf.nn.embedding_lookup() function returns the embedding at row 1 in the embedding matrix (twice): [0.3528825, 0.46448255].\n",
        "\n",
        "Keras provides a keras.layers.Embedding layer that handles the embedding matrix (trainable, by default); when the layer is created it initializes the embedding matrix randomly, and then when it is called with some category indices it returns the rows at those indices in the embedding matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_I8fq99sVwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "89dfb78d-08ef-411e-c1f4-6d7f0600e662"
      },
      "source": [
        "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets, output_dim=embedding_dim)\n",
        "embedding(cat_indices)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[ 0.01289039,  0.0191061 ],\n",
              "       [ 0.01639661, -0.01945841],\n",
              "       [ 0.00692506, -0.00518861],\n",
              "       [ 0.00692506, -0.00518861]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkdGAnXfs3SW",
        "colab_type": "text"
      },
      "source": [
        "Putting everything together, we can now create a Keras model that can process categorical features (along with regular numerical features) and learn an embedding for each category (as well as for each oov bucket)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXzesXIJsurb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regular_inputs = keras.layers.Input(shape=[8])\n",
        "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
        "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
        "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
        "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
        "\n",
        "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=[outputs])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d6incoUs9bO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "be3b6a68-f172-4fd7-8398-6973fe7c3cd3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None,)              0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 2)            12          lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 10)           0           input_1[0][0]                    \n",
            "                                                                 embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            11          concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 23\n",
            "Trainable params: 23\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3DdPdcLs_6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "1163cec5-1ccb-42cb-e49e-472e33323049"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model, \n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"LR\"\n",
        ")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djmBkb3DtvEw",
        "colab_type": "text"
      },
      "source": [
        "This model takes two inputs: a regular input containing eight numerical features per instance, plus a categorical input (containing one categorical feature per instance). It uses a Lambda layer to look up each category’s index, then it looks up the embeddings for these indices. Next, it concatenates the embeddings and the regular inputs in order to give the encoded inputs, which are ready to be fed to a neural network. We could add any kind of neural network at this point, but we just add a dense output layer, and we create the Keras model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4US4YUiSuPjf",
        "colab_type": "text"
      },
      "source": [
        "## TF Transform\n",
        "TensorFlow eXtended (TFX) an end-toend platform for productionizing TensorFlow models. First, to use a TFX component such as TF Transform, you must install it; it does not come bundled with TensorFlow. You then define your preprocessing function just once (in Python), by using TF Transform functions for scaling, bucketizing, and more. You can also use any TensorFlow operation you need. Here is what this preprocessing function might look like if we just had two features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1nKyR2XtIRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_transform as tft\n",
        "\n",
        "def preprocess(inputs):  # inputs is a batch of input features\n",
        "    median_age = inputs[\"housing_median_age\"]\n",
        "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
        "    standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
        "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
        "    return {\n",
        "        \"standardized_median_age\": standardized_age,\n",
        "        \"ocean_proximity_id\": ocean_proximity_id\n",
        "    }"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLiUhfgQ0LYS",
        "colab_type": "text"
      },
      "source": [
        "Next, TF Transform lets you apply this preprocess() function to the whole training set using Apache Beam (it provides an AnalyzeAndTransformDataset class that you can use for this purpose in your Apache Beam pipeline). In the process, it will also compute all the necessary statistics over the whole training set: in this example, the mean and standard deviation of the housing_median_age feature, and the vocabulary for the ocean_proximity feature. The components that compute these statistics are called analyzers.\n",
        "\n",
        "Importantly, TF Transform will also generate an equivalent TensorFlow Function that you can plug into the model you deploy. This TF Function includes some constants that correspond to all the all the necessary statistics computed by Apache Beam (the mean, standard deviation, and vocabulary).\n",
        "\n",
        "With the Data API, TFRecords, the Keras preprocessing layers, and TF Transform, you can build highly scalable input pipelines for training and benefit from fast and portable data preprocessing in production.\n",
        "\n",
        "But what if you just wanted to use a standard dataset? Well in that case, things are much simpler: just use TFDS!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trWNazmS0ajb",
        "colab_type": "text"
      },
      "source": [
        "## TF Datasets (TFDS)\n",
        "The TensorFlow Datasets project makes it very easy to download common datasets, from small ones like MNIST or Fashion MNIST to huge datasets like ImageNet. The list includes image datasets, text datasets (including translation datasets), and audio and video datasets. You can visit https:// homl.info/tfds to view the full list, along with a description of each dataset.\n",
        "\n",
        "TFDS is not bundled with TensorFlow, so you need to install the tensorflowdatasets library (e.g., using pip). Then call the tfds.load() function, and it will download the data you want (unless it was already downloaded earlier) and return the data as a dictionary of datasets (typically one for training and one for testing, but this depends on the dataset you choose). For example, let’s download MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEDx8QKcw9iV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "b22d6b3cbe3f465881076fc6411dd089",
            "59c52928d9654454aea31f00769fd800",
            "1ad38b68cdda4832b736593927738662",
            "19f64c60bf6c4803a7a6cca6dfaf2972",
            "b16c68ac494f464d91e8ee5603297a72",
            "7fa3da74b007484b89b0ebafa8d26069",
            "0ac2adee520d475eaca005ac5f5ffc82",
            "9263bb01633a4547b963f76e391469a4"
          ]
        },
        "outputId": "3d17f24f-2b02-4ced-d0f3-7e0f532add42"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "datasets = tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b22d6b3cbe3f465881076fc6411dd089",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33sX07ps1_13",
        "colab_type": "text"
      },
      "source": [
        "Note that each item in the dataset is a dictionary containing both the features and the labels. But Keras expects each item to be a tuple containing two elements (again, the features and the labels). You could transform the dataset using the map() method, like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2kNMs5b08bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
        "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
        "mnist_train = mnist_train.prefetch(1)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gygZsc02Ig_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f287b63-d008-4075-fa90-ba85fecedf14"
      },
      "source": [
        "for ele in mnist_train.take(1):\n",
        "    print(ele[0].shape, ele[1].shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 28, 28, 1) (32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDVwh4pG2H4Y",
        "colab_type": "text"
      },
      "source": [
        "But it’s simpler to ask the load() function to do this for you by setting as_super vised=True (obviously this works only for labeled datasets). You can also specify the batch size if you want. Then you can pass the dataset directly to your tf.keras model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWB3mt-s2D2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
        "mnist_train = dataset[\"train\"].prefetch(1)\n",
        "# model = keras.models.Sequential([...])\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\")\n",
        "# model.fit(mnist_train, epochs=5)"
      ],
      "execution_count": 82,
      "outputs": []
    }
  ]
}